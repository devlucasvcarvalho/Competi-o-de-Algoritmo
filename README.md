# ğŸ§  CompetiÃ§Ã£o de Algoritmo 1 â€” InteligÃªncia Computacional Aplicada

**Professor:** Roney Nogueira de Sousa  
**Disciplina:** InteligÃªncia Computacional Aplicada  

## ğŸ“˜ DescriÃ§Ã£o

Este projeto implementa a soluÃ§Ã£o da **CompetiÃ§Ã£o de Algoritmo 1**, conforme o edital fornecido pelo professor.  
O objetivo Ã© avaliar o desempenho de algoritmos de **classificaÃ§Ã£o supervisionada** em trÃªs bases de dados sintÃ©ticas clÃ¡ssicas:  
- `Two Moons`  
- `Banana`  
- `Ripley`  

O modelo escolhido foi um **Perceptron Multicamadas (MLP)** com **duas camadas ocultas de 5 neurÃ´nios cada**, desenvolvido em Python utilizando a biblioteca `scikit-learn`.

---

## âš™ï¸ Estrutura do Projeto

â”œâ”€â”€ notebook/
â”‚ â””â”€â”€ Competicao_Algoritmo1.ipynb # Notebook Colab completo e reprodutÃ­vel
â”œâ”€â”€ models/
â”‚ â””â”€â”€ mlp_two_moons.joblib # Modelo salvo (exemplo)
â”œâ”€â”€ predict.py # Script de inferÃªncia padronizado
â”œâ”€â”€ README.md # Este arquivo
â””â”€â”€ requirements.txt # DependÃªncias do projeto


---

## ğŸš€ Como Executar o Projeto

### ğŸ”¹ 1. Executar o Notebook no Google Colab

1. Acesse o Google Colab: [https://colab.research.google.com](https://colab.research.google.com)
2. FaÃ§a upload do arquivo `Competicao_Algoritmo1.ipynb`.
3. Execute **todas as cÃ©lulas em ordem** (Menu â†’ Executar tudo).  
4. O notebook:
   - Gera e/ou baixa os datasets (`Two Moons`, `Banana`, `Ripley`);
   - Treina o modelo MLP;
   - Avalia as mÃ©tricas de desempenho (AcurÃ¡cia, PrecisÃ£o, Recall, F1);
   - Calcula o tempo mÃ©dio de inferÃªncia por amostra (30 execuÃ§Ãµes).

---

### ğŸ”¹ 2. InferÃªncia via Script (`predict.py`)

ApÃ³s treinar o modelo, Ã© possÃ­vel realizar previsÃµes com o script de inferÃªncia padronizado:

```bash
python predict.py <modelo.joblib> <arquivo_de_entrada.csv> [arquivo_de_saida.csv] 

Exemplo:

python predict.py models/mlp_two_moons.joblib datasets/two_moons.csv preds.csv


O script gera um arquivo preds.csv com as previsÃµes (y_pred).

ğŸ§© Modelo Utilizado

Tipo: MLPClassifier (Multi-Layer Perceptron)
Biblioteca: scikit-learn
ParÃ¢metros:

MLPClassifier(
    hidden_layer_sizes=(5,5),
    activation='relu',
    solver='adam',
    max_iter=1000,
    random_state=42
)


O modelo foi avaliado com validaÃ§Ã£o cruzada StratifiedKFold (k=5) e 30 mediÃ§Ãµes de tempo por amostra, conforme o edital da competiÃ§Ã£o.

ğŸ“ˆ MÃ©tricas Avaliadas

Para cada dataset:

AcurÃ¡cia

PrecisÃ£o (macro)

Recall (macro)

F1-score (macro)

Tempo mÃ©dio de inferÃªncia por amostra

Desvios-padrÃ£o das mÃ©tricas nas dobras da validaÃ§Ã£o cruzada

O score final S segue o critÃ©rio:

S = 0.70Â·M - 0.20Â·ÏƒM + 0.10Â·T*


onde:

M Ã© a mÃ©dia das mÃ©tricas (Acc, Prec, Rec, F1);

ÏƒM Ã© a mÃ©dia dos desvios-padrÃ£o;

T* Ã© a normalizaÃ§Ã£o minâ€“max inversa do tempo mÃ©dio de inferÃªncia.

ğŸ§¾ DependÃªncias

As principais bibliotecas utilizadas foram:

scikit-learn==1.5.0
pandas==2.2.2
numpy==1.26.4
matplotlib==3.9.0
wget==3.2
joblib==1.4.2


No Colab, as dependÃªncias sÃ£o instaladas automaticamente com:

!pip install -q scikit-learn pandas matplotlib numpy wget joblib

ğŸ”’ Reprodutibilidade

Todas as sementes aleatÃ³rias (numpy, random) foram fixadas com SEED = 42.

O notebook Ã© totalmente reprodutÃ­vel e roda do zero.

NÃ£o foram utilizados frameworks AutoML.

Foram respeitados os protocolos de validaÃ§Ã£o e as regras do edital.

âœï¸ ObservaÃ§Ãµes

O modelo Ã© leve, estÃ¡vel e possui baixo tempo de inferÃªncia.

O relatÃ³rio tÃ©cnico com mÃ©tricas e anÃ¡lises estÃ¡ incluÃ­do em PDF na submissÃ£o.

Este repositÃ³rio segue as regras de submissÃ£o descritas no edital da competiÃ§Ã£o.
