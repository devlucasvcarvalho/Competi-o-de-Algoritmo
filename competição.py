# -*- coding: utf-8 -*-
"""Competição.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JilkowQeFgBnC9L9f8z0Z6DwXfGVxTln
"""

!pip install -q scikit-learn pandas matplotlib numpy wget joblib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time, random, joblib, wget
from sklearn.datasets import make_moons
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Reprodutibilidade
SEED = 42
np.random.seed(SEED)
random.seed(SEED)

MLPClassifier(hidden_layer_sizes=(5,5), activation='relu',
              solver='adam', max_iter=1000, random_state=SEED)

# === DATASETS ===
# Two Moons (gerar via sklearn)
X_tm, y_tm = make_moons(n_samples=5000, noise=0.25, random_state=SEED)
df_tm = pd.DataFrame({"x1": X_tm[:,0], "x2": X_tm[:,1], "y": y_tm})
df_tm.to_csv("two_moons.csv", index=False)

# Banana e Ripley (baixar via wget)
wget.download('https://raw.githubusercontent.com/sauloafoliveira/cclw-mlm/master/local_datasets/datasets-7627-10826-banana.csv', 'banana.csv')
wget.download('https://raw.githubusercontent.com/sauloafoliveira/cclw-mlm/master/local_datasets/rip.csv', 'ripley.csv')

df_banana = pd.read_csv("banana.csv")
df_rip = pd.read_csv("ripley.csv")

datasets = {
    "TwoMoons": (df_tm[["x1","x2"]].values, df_tm["y"].values),
    "Banana": (df_banana[df_banana.columns[:-1]].values, df_banana[df_banana.columns[-1]].values),
    "Ripley": (df_rip[df_rip.columns[:-1]].values, df_rip[df_rip.columns[-1]].values)
}

# === FUNÇÃO DE AVALIAÇÃO PADRONIZADA ===
def evaluate_model(model, X, y, n_splits=5, time_runs=30):
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)
    accs, precs, recs, f1s, times = [], [], [], [], []

    for train_idx, test_idx in skf.split(X, y):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        scaler = StandardScaler().fit(X_train)
        X_train_s, X_test_s = scaler.transform(X_train), scaler.transform(X_test)

        model.fit(X_train_s, y_train)

        # tempo médio por amostra (30 execuções)
        n_test = len(X_test_s)
        t_runs = []
        for _ in range(time_runs):
            t0 = time.perf_counter()
            _ = model.predict(X_test_s)
            t1 = time.perf_counter()
            t_runs.append((t1 - t0)/n_test)
        times.append(np.mean(t_runs))

        y_pred = model.predict(X_test_s)
        accs.append(accuracy_score(y_test, y_pred))
        precs.append(precision_score(y_test, y_pred, average="macro", zero_division=0))
        recs.append(recall_score(y_test, y_pred, average="macro", zero_division=0))
        f1s.append(f1_score(y_test, y_pred, average="macro", zero_division=0))

    results = {
        "Acc_mean": np.mean(accs), "Acc_std": np.std(accs),
        "Prec_mean": np.mean(precs), "Prec_std": np.std(precs),
        "Rec_mean": np.mean(recs), "Rec_std": np.std(recs),
        "F1_mean": np.mean(f1s), "F1_std": np.std(f1s),
        "T_mean": np.mean(times), "T_std": np.std(times)
    }
    return results

# === TREINO E AVALIAÇÃO DO MLP ===
model_mlp = MLPClassifier(hidden_layer_sizes=(5,5),
                          activation='relu',
                          solver='adam',
                          max_iter=1000,
                          random_state=SEED)

results_all = {}
for name, (X, y) in datasets.items():
    print(f"\n=== Dataset: {name} ===")
    res = evaluate_model(model_mlp, X, y)
    results_all[name] = res
    print(f"Acurácia: {res['Acc_mean']:.4f} ± {res['Acc_std']:.4f}")
    print(f"Precisão: {res['Prec_mean']:.4f} ± {res['Prec_std']:.4f}")
    print(f"Recall:   {res['Rec_mean']:.4f} ± {res['Rec_std']:.4f}")
    print(f"F1-score: {res['F1_mean']:.4f} ± {res['F1_std']:.4f}")
    print(f"Tempo médio por amostra: {res['T_mean']*1000:.6f} ms ± {res['T_std']*1000:.6f} ms")

import joblib

scaler = StandardScaler().fit(X_tm)
model_mlp.fit(scaler.transform(X_tm), y_tm)
bundle = {"model": model_mlp, "scaler": scaler, "meta": {"dataset": "TwoMoons", "seed": SEED}}
joblib.dump(bundle, "mlp_two_moons.joblib")
print("Modelo salvo em mlp_two_moons.joblib")